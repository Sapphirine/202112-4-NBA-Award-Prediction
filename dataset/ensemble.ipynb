{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZBnUXIR9oVs",
        "outputId": "018b53ad-33e4-45d8-99fc-708bac42659b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWupr4HpAf0P",
        "outputId": "390633aa-a293-47ca-fa3f-e26ef2ece958"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "path = '/content/drive/My Drive'\n",
        "sys.path.append(path)\n",
        "os.chdir(path)\n",
        "%cd BDA 21"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/BDA 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArrAbeDR40Fz"
      },
      "source": [
        "load_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i7ew6Jq41xv"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_dataset(path):\n",
        "    data = pd.read_csv(path)\n",
        "    y = data.loc[:, \"label\"].values.astype(int)\n",
        "    X = data.iloc[:, 3:9].values\n",
        "    return X, y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1kXoDWX9zCZ"
      },
      "source": [
        "resample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf1xIFhoAeS6",
        "outputId": "d3be6727-0691-4ee1-bb7f-d7c5f2b3978f"
      },
      "source": [
        "!pip install pytorch-tabnet\n",
        "!pip install imblearn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-3.1.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.62.3)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.10.0+cu111)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.0.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.10.0.2)\n",
            "Installing collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-3.1.1\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.8.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuUzywCJAec1"
      },
      "source": [
        "from imblearn.over_sampling import * \n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def resampling(X, y):\n",
        "    kmeans_sm = KMeansSMOTE(random_state=42, cluster_balance_threshold=0.05)\n",
        "    X_res, y_res = kmeans_sm.fit_resample(X, y)\n",
        "    # svm_sm = SVMSMOTE(random_state=42)\n",
        "    # X_res2, y_res2 = svm_sm.fit_resample(X, y)\n",
        "    # return np.vstack((X_res, X_res2)), np.hstack((y_res, y_res2))\n",
        "    return X_res, y_res\n",
        "\n",
        "\n",
        "def data_preprocess(X):\n",
        "    return normalize(X, axis=0)\n",
        "\n",
        "\n",
        "def cross_validation(X_train, Y_train):\n",
        "    five_fold_data = list()\n",
        "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "    for train_index, eval_index in kf.split(X_train):\n",
        "        x_train, x_eval = X_train[train_index], X_train[eval_index]\n",
        "        y_train, y_eval = Y_train[train_index], Y_train[eval_index]\n",
        "        five_fold_data.append([(x_train, y_train), (x_eval, y_eval)])\n",
        "    return five_fold_data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "145k7oNa5RMo"
      },
      "source": [
        "use tabnet with pretraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzSee_QP5Qb5"
      },
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, confusion_matrix\n",
        "\n",
        "\n",
        "def train(five_fold_data, X_pretrain):\n",
        "    unsupervised_model = TabNetPretrainer(\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    mask_type='entmax' # \"sparsemax\"\n",
        "    )\n",
        "\n",
        "    unsupervised_model.fit(\n",
        "        X_train=X_pretrain,\n",
        "        eval_set=[X_pretrain],\n",
        "        pretraining_ratio=0.8,\n",
        "    )\n",
        "    clf = TabNetClassifier(\n",
        "        optimizer_fn=torch.optim.Adam,\n",
        "        optimizer_params=dict(lr=2e-2),\n",
        "        scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
        "                        \"gamma\":0.9},\n",
        "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "        mask_type='entmax' # This will be overwritten if using pretrain model\n",
        "    )\n",
        "\n",
        "    model_sets = list()\n",
        "    # indices = np.random.choice(5, size=3, replace=False)\n",
        "    for i, [(x_train, y_train), (x_eval, y_eval)] in enumerate(five_fold_data):\n",
        "        clf.fit(\n",
        "            X_train=x_train, y_train=y_train, \n",
        "            eval_set=[(x_train, y_train), (x_eval, y_eval)],\n",
        "            eval_name=['train', 'valid'],\n",
        "            eval_metric=['auc', 'accuracy'],\n",
        "            from_unsupervised=unsupervised_model\n",
        "    )\n",
        "        # if i in indices:\n",
        "        model_sets.append(clf)\n",
        "    return model_sets\n",
        "\n",
        "\n",
        "def tabnet_test(model_sets, X_test, y_test):\n",
        "    results = np.zeros((5, len(X_test)))\n",
        "    for i, model in enumerate(model_sets):\n",
        "        preds = model.predict_proba(X_test)\n",
        "        results[i] = preds[:, 1]\n",
        "    best_roc_auc = 0.5\n",
        "    best_factor = 0.85\n",
        "    # for factor in np.arange(0.7, 0.95, 0.1):\n",
        "    #     score = results.mean(axis=-2) * (0.5/factor)\n",
        "    #     auc = roc_auc_score(y_test, score)\n",
        "    #     if auc > best_roc_auc:\n",
        "    #         best_roc_auc = auc \n",
        "    #         best_factor = factor\n",
        "    score = results.mean(axis=-2) * (0.5/best_factor)\n",
        "    auc = roc_auc_score(y_test, score)    \n",
        "    pred = (score > 0.5).astype(int)\n",
        "    recall = recall_score(y_true=y_test, y_pred=pred)\n",
        "    acc = accuracy_score(y_pred=pred, y_true=y_test)\n",
        "    return acc, auc, recall, score"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG0eKmMqohSd"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "\n",
        "def tree_decider(X_train, y_train, X_test, y_test):\n",
        "    clf = AdaBoostClassifier(n_estimators=100, random_state=0)  \n",
        "    clf.fit(X_train, y_train)\n",
        "    best_roc_auc = 0.5\n",
        "    best_factor = 0.5\n",
        "    for factor in np.arange(0.25, 0.5, 0.1):\n",
        "        prob = clf.predict_proba(X_test)[:, 1] * (0.5/best_factor)\n",
        "        auc = roc_auc_score(y_test, prob, average=\"samples\")\n",
        "        if auc > best_roc_auc:\n",
        "            best_roc_auc = auc \n",
        "            best_factor = factor\n",
        "    prob = clf.predict_proba(X_test)[:, 1] * (0.5/best_factor)\n",
        "    pred = np.where(prob > 0.5, 1, 0)\n",
        "    acc = accuracy_score(y_pred=pred, y_true=y_test)\n",
        "    auc = roc_auc_score(y_test, prob, average=\"samples\")\n",
        "    recall = recall_score(y_test, pred)\n",
        "    return acc, auc, recall, prob"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpMwCJVWs1XV"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "\n",
        "def linear_model(train_X, train_y, test_X, test_y):\n",
        "    clf = LogisticRegressionCV(cv=5, penalty=\"l2\", random_state=42, multi_class=\"ovr\", solver=\"liblinear\")\n",
        "    clf.fit(train_X, train_y)\n",
        "    best_roc_auc = 0.5\n",
        "    best_factor = 0.5\n",
        "    for factor in np.arange(0.25, 0.5, 0.1):\n",
        "        prob = clf.predict_proba(test_X)[:, 1] * (0.5/factor)\n",
        "        auc = roc_auc_score(test_y, prob, average=\"samples\")\n",
        "        if auc > best_roc_auc:\n",
        "            best_roc_auc = auc \n",
        "            best_factor = factor\n",
        "    prob = clf.predict_proba(test_X)[:, 1] * (0.5/best_factor)\n",
        "    pred = np.where(prob > 0.5, 1, 0)\n",
        "    acc = accuracy_score(y_pred=pred, y_true=test_y)\n",
        "    auc = roc_auc_score(test_y, prob, average=\"samples\")\n",
        "    recall = recall_score(test_y, pred)\n",
        "    return acc, auc, recall, prob"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCGuMdnvqPq1"
      },
      "source": [
        "ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQwcB7TYqOzD"
      },
      "source": [
        "def ensemble(results_tabnet, results_linear, results_tree, y_test):\n",
        "    final_results = np.empty((len(results_tabnet)))\n",
        "    score_avg = (results_tabnet + results_linear + results_tree) / 3\n",
        "    for i in range(len(results_tabnet)):\n",
        "        final_results[i] = (score_avg[i] > 0.5).astype(int)\n",
        "    cf_matrix = confusion_matrix(y_test, final_results)\n",
        "    return cf_matrix"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvSAu7WDt0Kc"
      },
      "source": [
        "def full_train():\n",
        "    train_X, train_y = load_dataset(\"player_stats_2019_2020.csv\")\n",
        "    test_X, test_y = load_dataset(\"player_stats_2020_2021.csv\")\n",
        "    train_X_norm = data_preprocess(train_X)\n",
        "    test_X_norm = data_preprocess(test_X)\n",
        "    acc, auc, recall, results_linear = linear_model(train_X_norm, train_y, test_X_norm, test_y)\n",
        "    print(\"linear model: acc is {:.5f}, auc is {:.5f} and recall is {:.5f}\".format(acc, auc, recall))\n",
        "    acc, auc, recall, results_tree = tree_decider(train_X_norm, train_y, test_X_norm, test_y)\n",
        "    print(\"tree model: acc is {:.5f}, auc is {:.5f} and recall is {:.5f}\".format(acc, auc, recall))\n",
        "    \n",
        "    train_X_re, train_y_re = resampling(train_X, train_y)\n",
        "\n",
        "    five_fold_data = cross_validation(train_X_re, train_y_re)\n",
        "    models = train(five_fold_data, train_X)\n",
        "    acc_score, auc_score, the_recall_score, results_tabnet = tabnet_test(models, test_X, test_y)\n",
        "    print(\"accuracy score is {:.5f}, roc auc score is {:.5f} and recall score is {:.5f}\".format(acc_score, auc_score, the_recall_score))\n",
        "\n",
        "    return results_tabnet, results_linear, results_tree, test_y"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF1kwCxrupcX",
        "outputId": "0225c522-605d-44eb-f018-57b6e9ffa9a7"
      },
      "source": [
        "results_tabnet, results_linear, results_tree, test_y = full_train()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear model: acc is 0.97222, auc is 0.97321 and recall is 0.46667\n",
            "tree model: acc is 0.90000, auc is 0.93517 and recall is 0.86667\n",
            "Device used : cpu\n",
            "epoch 0  | loss: 7.01153 | val_0_unsup_loss: 431.34521|  0:00:00s\n",
            "epoch 1  | loss: 5.52148 | val_0_unsup_loss: 126.34342|  0:00:00s\n",
            "epoch 2  | loss: 3.85334 | val_0_unsup_loss: 48.94502|  0:00:00s\n",
            "epoch 3  | loss: 3.32467 | val_0_unsup_loss: 25.81126|  0:00:00s\n",
            "epoch 4  | loss: 2.9094  | val_0_unsup_loss: 23.02277|  0:00:00s\n",
            "epoch 5  | loss: 2.75511 | val_0_unsup_loss: 14.01752|  0:00:00s\n",
            "epoch 6  | loss: 2.79977 | val_0_unsup_loss: 7.89436 |  0:00:00s\n",
            "epoch 7  | loss: 2.34031 | val_0_unsup_loss: 5.02979 |  0:00:00s\n",
            "epoch 8  | loss: 2.31576 | val_0_unsup_loss: 5.18786 |  0:00:00s\n",
            "epoch 9  | loss: 2.01735 | val_0_unsup_loss: 6.05944 |  0:00:00s\n",
            "epoch 10 | loss: 1.97868 | val_0_unsup_loss: 6.39478 |  0:00:00s\n",
            "epoch 11 | loss: 1.91815 | val_0_unsup_loss: 6.39032 |  0:00:00s\n",
            "epoch 12 | loss: 1.83278 | val_0_unsup_loss: 6.82424 |  0:00:00s\n",
            "epoch 13 | loss: 1.77715 | val_0_unsup_loss: 8.09322 |  0:00:00s\n",
            "epoch 14 | loss: 1.6911  | val_0_unsup_loss: 10.60654|  0:00:01s\n",
            "epoch 15 | loss: 1.67307 | val_0_unsup_loss: 9.21598 |  0:00:01s\n",
            "epoch 16 | loss: 1.55225 | val_0_unsup_loss: 8.96353 |  0:00:01s\n",
            "epoch 17 | loss: 1.54638 | val_0_unsup_loss: 10.58712|  0:00:01s\n",
            "\n",
            "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_unsup_loss = 5.02979\n",
            "Best weights from best epoch are automatically used!\n",
            "Device used : cpu\n",
            "Loading weights from unsupervised pretraining\n",
            "epoch 0  | loss: 0.63185 | train_auc: 0.95338 | train_accuracy: 0.52295 | valid_auc: 0.9479  | valid_accuracy: 0.55072 |  0:00:00s\n",
            "epoch 1  | loss: 0.35771 | train_auc: 0.92291 | train_accuracy: 0.50845 | valid_auc: 0.87843 | valid_accuracy: 0.53623 |  0:00:00s\n",
            "epoch 2  | loss: 0.24064 | train_auc: 0.93881 | train_accuracy: 0.50725 | valid_auc: 0.89262 | valid_accuracy: 0.5314  |  0:00:00s\n",
            "epoch 3  | loss: 0.18927 | train_auc: 0.93588 | train_accuracy: 0.51087 | valid_auc: 0.88772 | valid_accuracy: 0.53623 |  0:00:00s\n",
            "epoch 4  | loss: 0.15534 | train_auc: 0.92841 | train_accuracy: 0.51329 | valid_auc: 0.88543 | valid_accuracy: 0.53623 |  0:00:00s\n",
            "epoch 5  | loss: 0.11396 | train_auc: 0.91942 | train_accuracy: 0.51812 | valid_auc: 0.88371 | valid_accuracy: 0.54589 |  0:00:00s\n",
            "epoch 6  | loss: 0.09081 | train_auc: 0.91287 | train_accuracy: 0.52899 | valid_auc: 0.86326 | valid_accuracy: 0.56522 |  0:00:00s\n",
            "epoch 7  | loss: 0.07848 | train_auc: 0.91135 | train_accuracy: 0.53502 | valid_auc: 0.86162 | valid_accuracy: 0.57488 |  0:00:00s\n",
            "epoch 8  | loss: 0.0615  | train_auc: 0.90891 | train_accuracy: 0.54106 | valid_auc: 0.85691 | valid_accuracy: 0.57488 |  0:00:00s\n",
            "epoch 9  | loss: 0.0639  | train_auc: 0.8916  | train_accuracy: 0.55435 | valid_auc: 0.8429  | valid_accuracy: 0.57488 |  0:00:00s\n",
            "epoch 10 | loss: 0.04944 | train_auc: 0.88031 | train_accuracy: 0.5628  | valid_auc: 0.8288  | valid_accuracy: 0.57971 |  0:00:00s\n",
            "epoch 11 | loss: 0.06747 | train_auc: 0.89799 | train_accuracy: 0.57005 | valid_auc: 0.83361 | valid_accuracy: 0.57488 |  0:00:00s\n",
            "epoch 12 | loss: 0.05279 | train_auc: 0.89688 | train_accuracy: 0.58333 | valid_auc: 0.83366 | valid_accuracy: 0.57971 |  0:00:00s\n",
            "epoch 13 | loss: 0.04464 | train_auc: 0.88651 | train_accuracy: 0.58816 | valid_auc: 0.82717 | valid_accuracy: 0.58937 |  0:00:00s\n",
            "epoch 14 | loss: 0.03683 | train_auc: 0.89245 | train_accuracy: 0.60628 | valid_auc: 0.83711 | valid_accuracy: 0.59903 |  0:00:01s\n",
            "epoch 15 | loss: 0.04171 | train_auc: 0.91564 | train_accuracy: 0.61353 | valid_auc: 0.87376 | valid_accuracy: 0.6087  |  0:00:01s\n",
            "epoch 16 | loss: 0.03827 | train_auc: 0.92637 | train_accuracy: 0.61957 | valid_auc: 0.89706 | valid_accuracy: 0.6087  |  0:00:01s\n",
            "epoch 17 | loss: 0.03471 | train_auc: 0.92476 | train_accuracy: 0.63406 | valid_auc: 0.90196 | valid_accuracy: 0.61836 |  0:00:01s\n",
            "epoch 18 | loss: 0.03165 | train_auc: 0.9227  | train_accuracy: 0.64251 | valid_auc: 0.89216 | valid_accuracy: 0.61836 |  0:00:01s\n",
            "epoch 19 | loss: 0.02068 | train_auc: 0.92169 | train_accuracy: 0.64493 | valid_auc: 0.88235 | valid_accuracy: 0.62319 |  0:00:01s\n",
            "epoch 20 | loss: 0.04017 | train_auc: 0.91807 | train_accuracy: 0.65459 | valid_auc: 0.87745 | valid_accuracy: 0.62319 |  0:00:01s\n",
            "epoch 21 | loss: 0.02274 | train_auc: 0.92048 | train_accuracy: 0.66425 | valid_auc: 0.87745 | valid_accuracy: 0.64251 |  0:00:01s\n",
            "epoch 22 | loss: 0.01503 | train_auc: 0.91807 | train_accuracy: 0.6715  | valid_auc: 0.88235 | valid_accuracy: 0.64734 |  0:00:01s\n",
            "epoch 23 | loss: 0.02199 | train_auc: 0.91687 | train_accuracy: 0.67512 | valid_auc: 0.88235 | valid_accuracy: 0.657   |  0:00:01s\n",
            "epoch 24 | loss: 0.01411 | train_auc: 0.91566 | train_accuracy: 0.68116 | valid_auc: 0.87255 | valid_accuracy: 0.657   |  0:00:01s\n",
            "epoch 25 | loss: 0.01254 | train_auc: 0.91687 | train_accuracy: 0.68478 | valid_auc: 0.86765 | valid_accuracy: 0.657   |  0:00:01s\n",
            "epoch 26 | loss: 0.01428 | train_auc: 0.91425 | train_accuracy: 0.69444 | valid_auc: 0.87255 | valid_accuracy: 0.657   |  0:00:01s\n",
            "epoch 27 | loss: 0.0184  | train_auc: 0.9161  | train_accuracy: 0.70048 | valid_auc: 0.87012 | valid_accuracy: 0.657   |  0:00:01s\n",
            "epoch 28 | loss: 0.01393 | train_auc: 0.91426 | train_accuracy: 0.70773 | valid_auc: 0.8775  | valid_accuracy: 0.657   |  0:00:02s\n",
            "epoch 29 | loss: 0.01217 | train_auc: 0.90555 | train_accuracy: 0.71135 | valid_auc: 0.87334 | valid_accuracy: 0.6715  |  0:00:02s\n",
            "epoch 30 | loss: 0.01001 | train_auc: 0.89467 | train_accuracy: 0.7186  | valid_auc: 0.88217 | valid_accuracy: 0.67633 |  0:00:02s\n",
            "epoch 31 | loss: 0.01094 | train_auc: 0.88225 | train_accuracy: 0.72464 | valid_auc: 0.86116 | valid_accuracy: 0.68116 |  0:00:02s\n",
            "epoch 32 | loss: 0.00856 | train_auc: 0.87397 | train_accuracy: 0.72464 | valid_auc: 0.84585 | valid_accuracy: 0.69082 |  0:00:02s\n",
            "epoch 33 | loss: 0.01214 | train_auc: 0.87447 | train_accuracy: 0.72947 | valid_auc: 0.83277 | valid_accuracy: 0.69082 |  0:00:02s\n",
            "epoch 34 | loss: 0.00619 | train_auc: 0.86687 | train_accuracy: 0.73551 | valid_auc: 0.83151 | valid_accuracy: 0.70531 |  0:00:02s\n",
            "epoch 35 | loss: 0.00698 | train_auc: 0.86669 | train_accuracy: 0.74034 | valid_auc: 0.84043 | valid_accuracy: 0.71498 |  0:00:02s\n",
            "epoch 36 | loss: 0.00837 | train_auc: 0.86731 | train_accuracy: 0.74517 | valid_auc: 0.83852 | valid_accuracy: 0.71981 |  0:00:02s\n",
            "epoch 37 | loss: 0.00554 | train_auc: 0.85637 | train_accuracy: 0.74638 | valid_auc: 0.82535 | valid_accuracy: 0.71981 |  0:00:02s\n",
            "epoch 38 | loss: 0.00538 | train_auc: 0.85417 | train_accuracy: 0.75242 | valid_auc: 0.82586 | valid_accuracy: 0.71981 |  0:00:02s\n",
            "epoch 39 | loss: 0.0031  | train_auc: 0.8578  | train_accuracy: 0.75483 | valid_auc: 0.83842 | valid_accuracy: 0.73913 |  0:00:02s\n",
            "epoch 40 | loss: 0.00504 | train_auc: 0.86482 | train_accuracy: 0.75845 | valid_auc: 0.84197 | valid_accuracy: 0.73913 |  0:00:02s\n",
            "epoch 41 | loss: 0.0086  | train_auc: 0.87036 | train_accuracy: 0.76449 | valid_auc: 0.8535  | valid_accuracy: 0.74396 |  0:00:03s\n",
            "epoch 42 | loss: 0.00531 | train_auc: 0.8696  | train_accuracy: 0.76932 | valid_auc: 0.85271 | valid_accuracy: 0.75362 |  0:00:03s\n",
            "epoch 43 | loss: 0.00532 | train_auc: 0.87666 | train_accuracy: 0.77536 | valid_auc: 0.85481 | valid_accuracy: 0.76812 |  0:00:03s\n",
            "epoch 44 | loss: 0.00524 | train_auc: 0.87734 | train_accuracy: 0.78019 | valid_auc: 0.86172 | valid_accuracy: 0.77295 |  0:00:03s\n",
            "epoch 45 | loss: 0.00555 | train_auc: 0.88113 | train_accuracy: 0.78623 | valid_auc: 0.86237 | valid_accuracy: 0.79227 |  0:00:03s\n",
            "epoch 46 | loss: 0.00204 | train_auc: 0.88617 | train_accuracy: 0.78986 | valid_auc: 0.86396 | valid_accuracy: 0.80676 |  0:00:03s\n",
            "epoch 47 | loss: 0.00443 | train_auc: 0.8949  | train_accuracy: 0.79469 | valid_auc: 0.88035 | valid_accuracy: 0.80676 |  0:00:03s\n",
            "epoch 48 | loss: 0.00405 | train_auc: 0.90092 | train_accuracy: 0.80193 | valid_auc: 0.89122 | valid_accuracy: 0.80676 |  0:00:03s\n",
            "epoch 49 | loss: 0.00713 | train_auc: 0.90525 | train_accuracy: 0.80676 | valid_auc: 0.89613 | valid_accuracy: 0.80676 |  0:00:03s\n",
            "epoch 50 | loss: 0.00312 | train_auc: 0.90949 | train_accuracy: 0.80676 | valid_auc: 0.90486 | valid_accuracy: 0.80676 |  0:00:03s\n",
            "epoch 51 | loss: 0.00154 | train_auc: 0.91212 | train_accuracy: 0.81159 | valid_auc: 0.90705 | valid_accuracy: 0.81159 |  0:00:03s\n",
            "epoch 52 | loss: 0.00979 | train_auc: 0.91894 | train_accuracy: 0.8128  | valid_auc: 0.90892 | valid_accuracy: 0.81159 |  0:00:03s\n",
            "epoch 53 | loss: 0.00314 | train_auc: 0.92539 | train_accuracy: 0.81401 | valid_auc: 0.91018 | valid_accuracy: 0.81159 |  0:00:03s\n",
            "epoch 54 | loss: 0.00228 | train_auc: 0.92606 | train_accuracy: 0.81643 | valid_auc: 0.90733 | valid_accuracy: 0.81159 |  0:00:03s\n",
            "epoch 55 | loss: 0.00383 | train_auc: 0.92651 | train_accuracy: 0.82005 | valid_auc: 0.90934 | valid_accuracy: 0.82126 |  0:00:04s\n",
            "epoch 56 | loss: 0.00386 | train_auc: 0.92584 | train_accuracy: 0.82488 | valid_auc: 0.92596 | valid_accuracy: 0.83092 |  0:00:04s\n",
            "epoch 57 | loss: 0.00347 | train_auc: 0.9283  | train_accuracy: 0.8285  | valid_auc: 0.92563 | valid_accuracy: 0.83575 |  0:00:04s\n",
            "epoch 58 | loss: 0.00536 | train_auc: 0.9291  | train_accuracy: 0.83696 | valid_auc: 0.92311 | valid_accuracy: 0.83575 |  0:00:04s\n",
            "epoch 59 | loss: 0.00243 | train_auc: 0.93032 | train_accuracy: 0.84179 | valid_auc: 0.92451 | valid_accuracy: 0.83575 |  0:00:04s\n",
            "epoch 60 | loss: 0.00254 | train_auc: 0.93436 | train_accuracy: 0.84541 | valid_auc: 0.9282  | valid_accuracy: 0.83575 |  0:00:04s\n",
            "epoch 61 | loss: 0.00233 | train_auc: 0.93897 | train_accuracy: 0.85145 | valid_auc: 0.9324  | valid_accuracy: 0.84058 |  0:00:04s\n",
            "epoch 62 | loss: 0.00248 | train_auc: 0.9428  | train_accuracy: 0.85749 | valid_auc: 0.93609 | valid_accuracy: 0.84541 |  0:00:04s\n",
            "epoch 63 | loss: 0.00158 | train_auc: 0.94681 | train_accuracy: 0.8599  | valid_auc: 0.93908 | valid_accuracy: 0.85507 |  0:00:04s\n",
            "epoch 64 | loss: 0.00162 | train_auc: 0.94974 | train_accuracy: 0.86232 | valid_auc: 0.94216 | valid_accuracy: 0.85507 |  0:00:04s\n",
            "epoch 65 | loss: 0.00358 | train_auc: 0.95046 | train_accuracy: 0.86353 | valid_auc: 0.94407 | valid_accuracy: 0.8599  |  0:00:04s\n",
            "epoch 66 | loss: 0.00162 | train_auc: 0.95064 | train_accuracy: 0.86473 | valid_auc: 0.93777 | valid_accuracy: 0.8599  |  0:00:04s\n",
            "epoch 67 | loss: 0.00513 | train_auc: 0.95214 | train_accuracy: 0.86957 | valid_auc: 0.94248 | valid_accuracy: 0.8599  |  0:00:04s\n",
            "epoch 68 | loss: 0.00205 | train_auc: 0.95298 | train_accuracy: 0.87198 | valid_auc: 0.9458  | valid_accuracy: 0.8599  |  0:00:04s\n",
            "epoch 69 | loss: 0.00162 | train_auc: 0.9545  | train_accuracy: 0.87319 | valid_auc: 0.94921 | valid_accuracy: 0.86957 |  0:00:05s\n",
            "epoch 70 | loss: 0.00465 | train_auc: 0.95469 | train_accuracy: 0.8744  | valid_auc: 0.94813 | valid_accuracy: 0.86957 |  0:00:05s\n",
            "epoch 71 | loss: 0.00268 | train_auc: 0.95693 | train_accuracy: 0.87319 | valid_auc: 0.94585 | valid_accuracy: 0.8744  |  0:00:05s\n",
            "epoch 72 | loss: 0.00245 | train_auc: 0.95871 | train_accuracy: 0.87319 | valid_auc: 0.94972 | valid_accuracy: 0.86957 |  0:00:05s\n",
            "epoch 73 | loss: 0.00675 | train_auc: 0.95936 | train_accuracy: 0.87319 | valid_auc: 0.95196 | valid_accuracy: 0.86957 |  0:00:05s\n",
            "epoch 74 | loss: 0.00908 | train_auc: 0.95789 | train_accuracy: 0.87681 | valid_auc: 0.95359 | valid_accuracy: 0.8744  |  0:00:05s\n",
            "epoch 75 | loss: 0.00231 | train_auc: 0.95418 | train_accuracy: 0.88164 | valid_auc: 0.96088 | valid_accuracy: 0.88406 |  0:00:05s\n",
            "epoch 76 | loss: 0.00171 | train_auc: 0.95546 | train_accuracy: 0.88406 | valid_auc: 0.9634  | valid_accuracy: 0.88889 |  0:00:05s\n",
            "epoch 77 | loss: 0.0084  | train_auc: 0.96144 | train_accuracy: 0.88527 | valid_auc: 0.96793 | valid_accuracy: 0.88889 |  0:00:05s\n",
            "epoch 78 | loss: 0.00269 | train_auc: 0.96325 | train_accuracy: 0.88889 | valid_auc: 0.96699 | valid_accuracy: 0.88889 |  0:00:05s\n",
            "epoch 79 | loss: 0.00308 | train_auc: 0.96556 | train_accuracy: 0.89251 | valid_auc: 0.96531 | valid_accuracy: 0.89372 |  0:00:05s\n",
            "epoch 80 | loss: 0.0018  | train_auc: 0.96635 | train_accuracy: 0.90097 | valid_auc: 0.96821 | valid_accuracy: 0.89372 |  0:00:05s\n",
            "epoch 81 | loss: 0.00521 | train_auc: 0.96939 | train_accuracy: 0.90459 | valid_auc: 0.97353 | valid_accuracy: 0.89372 |  0:00:05s\n",
            "epoch 82 | loss: 0.00777 | train_auc: 0.96932 | train_accuracy: 0.90821 | valid_auc: 0.97507 | valid_accuracy: 0.89855 |  0:00:06s\n",
            "epoch 83 | loss: 0.00632 | train_auc: 0.97255 | train_accuracy: 0.91184 | valid_auc: 0.9774  | valid_accuracy: 0.90821 |  0:00:06s\n",
            "epoch 84 | loss: 0.0042  | train_auc: 0.97258 | train_accuracy: 0.91546 | valid_auc: 0.98357 | valid_accuracy: 0.90821 |  0:00:06s\n",
            "epoch 85 | loss: 0.00151 | train_auc: 0.97351 | train_accuracy: 0.91667 | valid_auc: 0.98086 | valid_accuracy: 0.91304 |  0:00:06s\n",
            "epoch 86 | loss: 0.00445 | train_auc: 0.97332 | train_accuracy: 0.91667 | valid_auc: 0.99062 | valid_accuracy: 0.91787 |  0:00:06s\n",
            "epoch 87 | loss: 0.00433 | train_auc: 0.97568 | train_accuracy: 0.91667 | valid_auc: 0.99164 | valid_accuracy: 0.92271 |  0:00:06s\n",
            "epoch 88 | loss: 0.00413 | train_auc: 0.97716 | train_accuracy: 0.91667 | valid_auc: 0.99057 | valid_accuracy: 0.92271 |  0:00:06s\n",
            "epoch 89 | loss: 0.00195 | train_auc: 0.97608 | train_accuracy: 0.92029 | valid_auc: 0.98483 | valid_accuracy: 0.92271 |  0:00:06s\n",
            "epoch 90 | loss: 0.00179 | train_auc: 0.97794 | train_accuracy: 0.92754 | valid_auc: 0.98469 | valid_accuracy: 0.92754 |  0:00:06s\n",
            "epoch 91 | loss: 0.00135 | train_auc: 0.97665 | train_accuracy: 0.92754 | valid_auc: 0.98492 | valid_accuracy: 0.93237 |  0:00:06s\n",
            "epoch 92 | loss: 0.00276 | train_auc: 0.97776 | train_accuracy: 0.92874 | valid_auc: 0.98515 | valid_accuracy: 0.93237 |  0:00:06s\n",
            "epoch 93 | loss: 0.00278 | train_auc: 0.97748 | train_accuracy: 0.92995 | valid_auc: 0.98534 | valid_accuracy: 0.93237 |  0:00:06s\n",
            "epoch 94 | loss: 0.00292 | train_auc: 0.97842 | train_accuracy: 0.93116 | valid_auc: 0.98543 | valid_accuracy: 0.93237 |  0:00:06s\n",
            "epoch 95 | loss: 0.00693 | train_auc: 0.97803 | train_accuracy: 0.92995 | valid_auc: 0.98534 | valid_accuracy: 0.93237 |  0:00:06s\n",
            "epoch 96 | loss: 0.00134 | train_auc: 0.97968 | train_accuracy: 0.92995 | valid_auc: 0.98847 | valid_accuracy: 0.93237 |  0:00:07s\n",
            "epoch 97 | loss: 0.00206 | train_auc: 0.98072 | train_accuracy: 0.92995 | valid_auc: 0.98931 | valid_accuracy: 0.92754 |  0:00:07s\n",
            "epoch 98 | loss: 0.00202 | train_auc: 0.97976 | train_accuracy: 0.92995 | valid_auc: 0.99024 | valid_accuracy: 0.92754 |  0:00:07s\n",
            "epoch 99 | loss: 0.0067  | train_auc: 0.98117 | train_accuracy: 0.93357 | valid_auc: 0.99108 | valid_accuracy: 0.92754 |  0:00:07s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 91 and best_valid_accuracy = 0.93237\n",
            "Best weights from best epoch are automatically used!\n",
            "Loading weights from unsupervised pretraining\n",
            "epoch 0  | loss: 0.57127 | train_auc: 0.94904 | train_accuracy: 0.51812 | valid_auc: 0.96433 | valid_accuracy: 0.47343 |  0:00:00s\n",
            "epoch 1  | loss: 0.25477 | train_auc: 0.94791 | train_accuracy: 0.5157  | valid_auc: 0.97975 | valid_accuracy: 0.46377 |  0:00:00s\n",
            "epoch 2  | loss: 0.16155 | train_auc: 0.95326 | train_accuracy: 0.51932 | valid_auc: 0.97735 | valid_accuracy: 0.4686  |  0:00:00s\n",
            "epoch 3  | loss: 0.11987 | train_auc: 0.95069 | train_accuracy: 0.51691 | valid_auc: 0.96922 | valid_accuracy: 0.46377 |  0:00:00s\n",
            "epoch 4  | loss: 0.09882 | train_auc: 0.94571 | train_accuracy: 0.5157  | valid_auc: 0.9726  | valid_accuracy: 0.46377 |  0:00:00s\n",
            "epoch 5  | loss: 0.09528 | train_auc: 0.93623 | train_accuracy: 0.51932 | valid_auc: 0.96034 | valid_accuracy: 0.46377 |  0:00:00s\n",
            "epoch 6  | loss: 0.07374 | train_auc: 0.91815 | train_accuracy: 0.52536 | valid_auc: 0.93872 | valid_accuracy: 0.46377 |  0:00:00s\n",
            "epoch 7  | loss: 0.06727 | train_auc: 0.92147 | train_accuracy: 0.53986 | valid_auc: 0.92829 | valid_accuracy: 0.47343 |  0:00:00s\n",
            "epoch 8  | loss: 0.06374 | train_auc: 0.91044 | train_accuracy: 0.54589 | valid_auc: 0.91823 | valid_accuracy: 0.47826 |  0:00:00s\n",
            "epoch 9  | loss: 0.05865 | train_auc: 0.896   | train_accuracy: 0.55314 | valid_auc: 0.89539 | valid_accuracy: 0.48792 |  0:00:00s\n",
            "epoch 10 | loss: 0.04429 | train_auc: 0.8831  | train_accuracy: 0.56401 | valid_auc: 0.88322 | valid_accuracy: 0.50242 |  0:00:00s\n",
            "epoch 11 | loss: 0.05309 | train_auc: 0.858   | train_accuracy: 0.57246 | valid_auc: 0.86588 | valid_accuracy: 0.51208 |  0:00:00s\n",
            "epoch 12 | loss: 0.05013 | train_auc: 0.80698 | train_accuracy: 0.57609 | valid_auc: 0.80686 | valid_accuracy: 0.5314  |  0:00:00s\n",
            "epoch 13 | loss: 0.04234 | train_auc: 0.78298 | train_accuracy: 0.57729 | valid_auc: 0.77622 | valid_accuracy: 0.5314  |  0:00:00s\n",
            "epoch 14 | loss: 0.05122 | train_auc: 0.76323 | train_accuracy: 0.58454 | valid_auc: 0.76118 | valid_accuracy: 0.53623 |  0:00:01s\n",
            "epoch 15 | loss: 0.03155 | train_auc: 0.73983 | train_accuracy: 0.60386 | valid_auc: 0.75047 | valid_accuracy: 0.55556 |  0:00:01s\n",
            "epoch 16 | loss: 0.03604 | train_auc: 0.72353 | train_accuracy: 0.60628 | valid_auc: 0.72514 | valid_accuracy: 0.55072 |  0:00:01s\n",
            "epoch 17 | loss: 0.03254 | train_auc: 0.70028 | train_accuracy: 0.6099  | valid_auc: 0.68515 | valid_accuracy: 0.55556 |  0:00:01s\n",
            "epoch 18 | loss: 0.02707 | train_auc: 0.6495  | train_accuracy: 0.61353 | valid_auc: 0.66109 | valid_accuracy: 0.57005 |  0:00:01s\n",
            "epoch 19 | loss: 0.03542 | train_auc: 0.61082 | train_accuracy: 0.61836 | valid_auc: 0.60508 | valid_accuracy: 0.58937 |  0:00:01s\n",
            "epoch 20 | loss: 0.02904 | train_auc: 0.60767 | train_accuracy: 0.61111 | valid_auc: 0.59027 | valid_accuracy: 0.60386 |  0:00:01s\n",
            "epoch 21 | loss: 0.0229  | train_auc: 0.62857 | train_accuracy: 0.59662 | valid_auc: 0.61043 | valid_accuracy: 0.59903 |  0:00:01s\n",
            "epoch 22 | loss: 0.02545 | train_auc: 0.64723 | train_accuracy: 0.59662 | valid_auc: 0.64398 | valid_accuracy: 0.5942  |  0:00:01s\n",
            "epoch 23 | loss: 0.03607 | train_auc: 0.61787 | train_accuracy: 0.59179 | valid_auc: 0.61922 | valid_accuracy: 0.57971 |  0:00:01s\n",
            "epoch 24 | loss: 0.02077 | train_auc: 0.57958 | train_accuracy: 0.58937 | valid_auc: 0.59375 | valid_accuracy: 0.54589 |  0:00:01s\n",
            "epoch 25 | loss: 0.01919 | train_auc: 0.55721 | train_accuracy: 0.56159 | valid_auc: 0.57448 | valid_accuracy: 0.52657 |  0:00:01s\n",
            "epoch 26 | loss: 0.0169  | train_auc: 0.54889 | train_accuracy: 0.5471  | valid_auc: 0.57758 | valid_accuracy: 0.53623 |  0:00:01s\n",
            "epoch 27 | loss: 0.01904 | train_auc: 0.55797 | train_accuracy: 0.52899 | valid_auc: 0.59023 | valid_accuracy: 0.50725 |  0:00:02s\n",
            "epoch 28 | loss: 0.02024 | train_auc: 0.58095 | train_accuracy: 0.50362 | valid_auc: 0.6274  | valid_accuracy: 0.49758 |  0:00:02s\n",
            "epoch 29 | loss: 0.01286 | train_auc: 0.61144 | train_accuracy: 0.50966 | valid_auc: 0.63684 | valid_accuracy: 0.51691 |  0:00:02s\n",
            "epoch 30 | loss: 0.01298 | train_auc: 0.63494 | train_accuracy: 0.52295 | valid_auc: 0.66664 | valid_accuracy: 0.52657 |  0:00:02s\n",
            "\n",
            "Early stopping occurred at epoch 30 with best_epoch = 20 and best_valid_accuracy = 0.60386\n",
            "Best weights from best epoch are automatically used!\n",
            "Loading weights from unsupervised pretraining\n",
            "epoch 0  | loss: 0.556   | train_auc: 0.96003 | train_accuracy: 0.52899 | valid_auc: 0.94907 | valid_accuracy: 0.4686  |  0:00:00s\n",
            "epoch 1  | loss: 0.22389 | train_auc: 0.95915 | train_accuracy: 0.52053 | valid_auc: 0.94968 | valid_accuracy: 0.44928 |  0:00:00s\n",
            "epoch 2  | loss: 0.13673 | train_auc: 0.95397 | train_accuracy: 0.52174 | valid_auc: 0.94298 | valid_accuracy: 0.44928 |  0:00:00s\n",
            "epoch 3  | loss: 0.10978 | train_auc: 0.93365 | train_accuracy: 0.52295 | valid_auc: 0.93284 | valid_accuracy: 0.44928 |  0:00:00s\n",
            "epoch 4  | loss: 0.08838 | train_auc: 0.92986 | train_accuracy: 0.52295 | valid_auc: 0.94053 | valid_accuracy: 0.44928 |  0:00:00s\n",
            "epoch 5  | loss: 0.0798  | train_auc: 0.91687 | train_accuracy: 0.52899 | valid_auc: 0.93421 | valid_accuracy: 0.45894 |  0:00:00s\n",
            "epoch 6  | loss: 0.05799 | train_auc: 0.90074 | train_accuracy: 0.53623 | valid_auc: 0.89912 | valid_accuracy: 0.48309 |  0:00:00s\n",
            "epoch 7  | loss: 0.05708 | train_auc: 0.8933  | train_accuracy: 0.54227 | valid_auc: 0.88158 | valid_accuracy: 0.49275 |  0:00:00s\n",
            "epoch 8  | loss: 0.05576 | train_auc: 0.88213 | train_accuracy: 0.55314 | valid_auc: 0.86404 | valid_accuracy: 0.49758 |  0:00:00s\n",
            "epoch 9  | loss: 0.04934 | train_auc: 0.86973 | train_accuracy: 0.56159 | valid_auc: 0.86842 | valid_accuracy: 0.52174 |  0:00:00s\n",
            "epoch 10 | loss: 0.05081 | train_auc: 0.84615 | train_accuracy: 0.56643 | valid_auc: 0.83333 | valid_accuracy: 0.5314  |  0:00:00s\n",
            "epoch 11 | loss: 0.04195 | train_auc: 0.83375 | train_accuracy: 0.57367 | valid_auc: 0.81579 | valid_accuracy: 0.56039 |  0:00:00s\n",
            "epoch 12 | loss: 0.04558 | train_auc: 0.82134 | train_accuracy: 0.57729 | valid_auc: 0.80263 | valid_accuracy: 0.57005 |  0:00:00s\n",
            "epoch 13 | loss: 0.04918 | train_auc: 0.80769 | train_accuracy: 0.58575 | valid_auc: 0.80263 | valid_accuracy: 0.57005 |  0:00:01s\n",
            "epoch 14 | loss: 0.04081 | train_auc: 0.80769 | train_accuracy: 0.59541 | valid_auc: 0.80702 | valid_accuracy: 0.57005 |  0:00:01s\n",
            "epoch 15 | loss: 0.05446 | train_auc: 0.81638 | train_accuracy: 0.59903 | valid_auc: 0.81579 | valid_accuracy: 0.58937 |  0:00:01s\n",
            "epoch 16 | loss: 0.03105 | train_auc: 0.83499 | train_accuracy: 0.60145 | valid_auc: 0.82456 | valid_accuracy: 0.59903 |  0:00:01s\n",
            "epoch 17 | loss: 0.03239 | train_auc: 0.83871 | train_accuracy: 0.60507 | valid_auc: 0.83333 | valid_accuracy: 0.60386 |  0:00:01s\n",
            "epoch 18 | loss: 0.03474 | train_auc: 0.8433  | train_accuracy: 0.6087  | valid_auc: 0.83909 | valid_accuracy: 0.61353 |  0:00:01s\n",
            "epoch 19 | loss: 0.03002 | train_auc: 0.84948 | train_accuracy: 0.61473 | valid_auc: 0.85772 | valid_accuracy: 0.61353 |  0:00:01s\n",
            "epoch 20 | loss: 0.03459 | train_auc: 0.86677 | train_accuracy: 0.62198 | valid_auc: 0.87719 | valid_accuracy: 0.61353 |  0:00:01s\n",
            "epoch 21 | loss: 0.02165 | train_auc: 0.87987 | train_accuracy: 0.63164 | valid_auc: 0.88596 | valid_accuracy: 0.62319 |  0:00:01s\n",
            "epoch 22 | loss: 0.01911 | train_auc: 0.88483 | train_accuracy: 0.63647 | valid_auc: 0.88596 | valid_accuracy: 0.63285 |  0:00:01s\n",
            "epoch 23 | loss: 0.02023 | train_auc: 0.89298 | train_accuracy: 0.64614 | valid_auc: 0.89912 | valid_accuracy: 0.63768 |  0:00:01s\n",
            "epoch 24 | loss: 0.01839 | train_auc: 0.89487 | train_accuracy: 0.65338 | valid_auc: 0.90789 | valid_accuracy: 0.63768 |  0:00:01s\n",
            "epoch 25 | loss: 0.02046 | train_auc: 0.90148 | train_accuracy: 0.65821 | valid_auc: 0.90247 | valid_accuracy: 0.63768 |  0:00:01s\n",
            "epoch 26 | loss: 0.0197  | train_auc: 0.88631 | train_accuracy: 0.66908 | valid_auc: 0.89743 | valid_accuracy: 0.64734 |  0:00:02s\n",
            "epoch 27 | loss: 0.01864 | train_auc: 0.89003 | train_accuracy: 0.67271 | valid_auc: 0.89285 | valid_accuracy: 0.64251 |  0:00:02s\n",
            "epoch 28 | loss: 0.01705 | train_auc: 0.89208 | train_accuracy: 0.67874 | valid_auc: 0.88894 | valid_accuracy: 0.64251 |  0:00:02s\n",
            "epoch 29 | loss: 0.02646 | train_auc: 0.88582 | train_accuracy: 0.68478 | valid_auc: 0.85701 | valid_accuracy: 0.66184 |  0:00:02s\n",
            "epoch 30 | loss: 0.01772 | train_auc: 0.88862 | train_accuracy: 0.68961 | valid_auc: 0.84338 | valid_accuracy: 0.66667 |  0:00:02s\n",
            "epoch 31 | loss: 0.01815 | train_auc: 0.88368 | train_accuracy: 0.69324 | valid_auc: 0.85616 | valid_accuracy: 0.6715  |  0:00:02s\n",
            "epoch 32 | loss: 0.01879 | train_auc: 0.89656 | train_accuracy: 0.69686 | valid_auc: 0.87583 | valid_accuracy: 0.67633 |  0:00:02s\n",
            "epoch 33 | loss: 0.01442 | train_auc: 0.91772 | train_accuracy: 0.70531 | valid_auc: 0.90384 | valid_accuracy: 0.68599 |  0:00:02s\n",
            "epoch 34 | loss: 0.01561 | train_auc: 0.9261  | train_accuracy: 0.71014 | valid_auc: 0.91704 | valid_accuracy: 0.69082 |  0:00:02s\n",
            "epoch 35 | loss: 0.01883 | train_auc: 0.933   | train_accuracy: 0.72222 | valid_auc: 0.92105 | valid_accuracy: 0.69082 |  0:00:02s\n",
            "epoch 36 | loss: 0.01462 | train_auc: 0.9268  | train_accuracy: 0.72826 | valid_auc: 0.92544 | valid_accuracy: 0.69565 |  0:00:02s\n",
            "epoch 37 | loss: 0.01327 | train_auc: 0.92432 | train_accuracy: 0.73671 | valid_auc: 0.92544 | valid_accuracy: 0.69565 |  0:00:02s\n",
            "epoch 38 | loss: 0.01779 | train_auc: 0.93052 | train_accuracy: 0.74396 | valid_auc: 0.92544 | valid_accuracy: 0.70048 |  0:00:02s\n",
            "epoch 39 | loss: 0.00832 | train_auc: 0.92556 | train_accuracy: 0.75483 | valid_auc: 0.93421 | valid_accuracy: 0.71498 |  0:00:02s\n",
            "epoch 40 | loss: 0.00921 | train_auc: 0.92928 | train_accuracy: 0.75845 | valid_auc: 0.93421 | valid_accuracy: 0.72464 |  0:00:03s\n",
            "epoch 41 | loss: 0.01574 | train_auc: 0.93052 | train_accuracy: 0.76932 | valid_auc: 0.9386  | valid_accuracy: 0.7343  |  0:00:03s\n",
            "epoch 42 | loss: 0.01182 | train_auc: 0.93052 | train_accuracy: 0.77174 | valid_auc: 0.9386  | valid_accuracy: 0.74396 |  0:00:03s\n",
            "epoch 43 | loss: 0.02807 | train_auc: 0.933   | train_accuracy: 0.77657 | valid_auc: 0.94298 | valid_accuracy: 0.74879 |  0:00:03s\n",
            "epoch 44 | loss: 0.00645 | train_auc: 0.93548 | train_accuracy: 0.78382 | valid_auc: 0.94298 | valid_accuracy: 0.75845 |  0:00:03s\n",
            "epoch 45 | loss: 0.01082 | train_auc: 0.93672 | train_accuracy: 0.79348 | valid_auc: 0.94298 | valid_accuracy: 0.75845 |  0:00:03s\n",
            "epoch 46 | loss: 0.0122  | train_auc: 0.93921 | train_accuracy: 0.7971  | valid_auc: 0.94298 | valid_accuracy: 0.76812 |  0:00:03s\n",
            "epoch 47 | loss: 0.01462 | train_auc: 0.94169 | train_accuracy: 0.80072 | valid_auc: 0.94737 | valid_accuracy: 0.76812 |  0:00:03s\n",
            "epoch 48 | loss: 0.01524 | train_auc: 0.94293 | train_accuracy: 0.80676 | valid_auc: 0.94737 | valid_accuracy: 0.76812 |  0:00:03s\n",
            "epoch 49 | loss: 0.00746 | train_auc: 0.94293 | train_accuracy: 0.8128  | valid_auc: 0.94737 | valid_accuracy: 0.76812 |  0:00:03s\n",
            "epoch 50 | loss: 0.00566 | train_auc: 0.94293 | train_accuracy: 0.81643 | valid_auc: 0.94737 | valid_accuracy: 0.78261 |  0:00:03s\n",
            "epoch 51 | loss: 0.00642 | train_auc: 0.94293 | train_accuracy: 0.81643 | valid_auc: 0.94737 | valid_accuracy: 0.78261 |  0:00:03s\n",
            "epoch 52 | loss: 0.00539 | train_auc: 0.94293 | train_accuracy: 0.82729 | valid_auc: 0.94737 | valid_accuracy: 0.78744 |  0:00:03s\n",
            "epoch 53 | loss: 0.00526 | train_auc: 0.94417 | train_accuracy: 0.8285  | valid_auc: 0.94737 | valid_accuracy: 0.78744 |  0:00:04s\n",
            "epoch 54 | loss: 0.00705 | train_auc: 0.94417 | train_accuracy: 0.83092 | valid_auc: 0.94737 | valid_accuracy: 0.78744 |  0:00:04s\n",
            "epoch 55 | loss: 0.00681 | train_auc: 0.94665 | train_accuracy: 0.83213 | valid_auc: 0.94737 | valid_accuracy: 0.78744 |  0:00:04s\n",
            "epoch 56 | loss: 0.0158  | train_auc: 0.94665 | train_accuracy: 0.83454 | valid_auc: 0.94737 | valid_accuracy: 0.78744 |  0:00:04s\n",
            "epoch 57 | loss: 0.01833 | train_auc: 0.94789 | train_accuracy: 0.83937 | valid_auc: 0.94737 | valid_accuracy: 0.78744 |  0:00:04s\n",
            "epoch 58 | loss: 0.0102  | train_auc: 0.94789 | train_accuracy: 0.8442  | valid_auc: 0.94737 | valid_accuracy: 0.78261 |  0:00:04s\n",
            "epoch 59 | loss: 0.01068 | train_auc: 0.95037 | train_accuracy: 0.8442  | valid_auc: 0.95614 | valid_accuracy: 0.7971  |  0:00:04s\n",
            "epoch 60 | loss: 0.0063  | train_auc: 0.95285 | train_accuracy: 0.84662 | valid_auc: 0.95614 | valid_accuracy: 0.80676 |  0:00:04s\n",
            "epoch 61 | loss: 0.00694 | train_auc: 0.95409 | train_accuracy: 0.85024 | valid_auc: 0.95614 | valid_accuracy: 0.81159 |  0:00:04s\n",
            "epoch 62 | loss: 0.00643 | train_auc: 0.95533 | train_accuracy: 0.85145 | valid_auc: 0.95614 | valid_accuracy: 0.82126 |  0:00:04s\n",
            "epoch 63 | loss: 0.00524 | train_auc: 0.95533 | train_accuracy: 0.85145 | valid_auc: 0.96053 | valid_accuracy: 0.82126 |  0:00:04s\n",
            "epoch 64 | loss: 0.00674 | train_auc: 0.95782 | train_accuracy: 0.85507 | valid_auc: 0.96053 | valid_accuracy: 0.82126 |  0:00:04s\n",
            "epoch 65 | loss: 0.00385 | train_auc: 0.9603  | train_accuracy: 0.85628 | valid_auc: 0.96053 | valid_accuracy: 0.82126 |  0:00:04s\n",
            "epoch 66 | loss: 0.00697 | train_auc: 0.9603  | train_accuracy: 0.8587  | valid_auc: 0.96053 | valid_accuracy: 0.82126 |  0:00:04s\n",
            "epoch 67 | loss: 0.00813 | train_auc: 0.9603  | train_accuracy: 0.86111 | valid_auc: 0.96053 | valid_accuracy: 0.82609 |  0:00:05s\n",
            "epoch 68 | loss: 0.00954 | train_auc: 0.9603  | train_accuracy: 0.86353 | valid_auc: 0.96053 | valid_accuracy: 0.82609 |  0:00:05s\n",
            "epoch 69 | loss: 0.00716 | train_auc: 0.96154 | train_accuracy: 0.86594 | valid_auc: 0.96053 | valid_accuracy: 0.82609 |  0:00:05s\n",
            "epoch 70 | loss: 0.00401 | train_auc: 0.96278 | train_accuracy: 0.86594 | valid_auc: 0.96053 | valid_accuracy: 0.82609 |  0:00:05s\n",
            "epoch 71 | loss: 0.0031  | train_auc: 0.96278 | train_accuracy: 0.86594 | valid_auc: 0.96491 | valid_accuracy: 0.82126 |  0:00:05s\n",
            "epoch 72 | loss: 0.00322 | train_auc: 0.96402 | train_accuracy: 0.87198 | valid_auc: 0.96053 | valid_accuracy: 0.82126 |  0:00:05s\n",
            "epoch 73 | loss: 0.0047  | train_auc: 0.96402 | train_accuracy: 0.8756  | valid_auc: 0.96053 | valid_accuracy: 0.82126 |  0:00:05s\n",
            "epoch 74 | loss: 0.00619 | train_auc: 0.96526 | train_accuracy: 0.87681 | valid_auc: 0.96491 | valid_accuracy: 0.81643 |  0:00:05s\n",
            "epoch 75 | loss: 0.00392 | train_auc: 0.9665  | train_accuracy: 0.88043 | valid_auc: 0.96491 | valid_accuracy: 0.81643 |  0:00:05s\n",
            "epoch 76 | loss: 0.00242 | train_auc: 0.9665  | train_accuracy: 0.88406 | valid_auc: 0.96491 | valid_accuracy: 0.81643 |  0:00:05s\n",
            "epoch 77 | loss: 0.00341 | train_auc: 0.96774 | train_accuracy: 0.88406 | valid_auc: 0.96491 | valid_accuracy: 0.83092 |  0:00:05s\n",
            "epoch 78 | loss: 0.00604 | train_auc: 0.96774 | train_accuracy: 0.88527 | valid_auc: 0.96491 | valid_accuracy: 0.83092 |  0:00:05s\n",
            "epoch 79 | loss: 0.00415 | train_auc: 0.97146 | train_accuracy: 0.89251 | valid_auc: 0.96053 | valid_accuracy: 0.83575 |  0:00:05s\n",
            "epoch 80 | loss: 0.00248 | train_auc: 0.97146 | train_accuracy: 0.89614 | valid_auc: 0.96053 | valid_accuracy: 0.84058 |  0:00:05s\n",
            "epoch 81 | loss: 0.00464 | train_auc: 0.97146 | train_accuracy: 0.90459 | valid_auc: 0.96053 | valid_accuracy: 0.84541 |  0:00:06s\n",
            "epoch 82 | loss: 0.00316 | train_auc: 0.97395 | train_accuracy: 0.90459 | valid_auc: 0.96491 | valid_accuracy: 0.85024 |  0:00:06s\n",
            "epoch 83 | loss: 0.00458 | train_auc: 0.97395 | train_accuracy: 0.90459 | valid_auc: 0.96491 | valid_accuracy: 0.85507 |  0:00:06s\n",
            "epoch 84 | loss: 0.00275 | train_auc: 0.97519 | train_accuracy: 0.90338 | valid_auc: 0.96491 | valid_accuracy: 0.8599  |  0:00:06s\n",
            "epoch 85 | loss: 0.00484 | train_auc: 0.97519 | train_accuracy: 0.90459 | valid_auc: 0.96491 | valid_accuracy: 0.8599  |  0:00:06s\n",
            "epoch 86 | loss: 0.01617 | train_auc: 0.97643 | train_accuracy: 0.9058  | valid_auc: 0.96491 | valid_accuracy: 0.8599  |  0:00:06s\n",
            "epoch 87 | loss: 0.00369 | train_auc: 0.97767 | train_accuracy: 0.90821 | valid_auc: 0.96491 | valid_accuracy: 0.86473 |  0:00:06s\n",
            "epoch 88 | loss: 0.00384 | train_auc: 0.97767 | train_accuracy: 0.91063 | valid_auc: 0.96491 | valid_accuracy: 0.86473 |  0:00:06s\n",
            "epoch 89 | loss: 0.00293 | train_auc: 0.97891 | train_accuracy: 0.91184 | valid_auc: 0.9693  | valid_accuracy: 0.86473 |  0:00:06s\n",
            "epoch 90 | loss: 0.00233 | train_auc: 0.98263 | train_accuracy: 0.91184 | valid_auc: 0.97368 | valid_accuracy: 0.86473 |  0:00:06s\n",
            "epoch 91 | loss: 0.00406 | train_auc: 0.98263 | train_accuracy: 0.91425 | valid_auc: 0.97368 | valid_accuracy: 0.8744  |  0:00:06s\n",
            "epoch 92 | loss: 0.00212 | train_auc: 0.98263 | train_accuracy: 0.91546 | valid_auc: 0.98246 | valid_accuracy: 0.8744  |  0:00:06s\n",
            "epoch 93 | loss: 0.0028  | train_auc: 0.98263 | train_accuracy: 0.9215  | valid_auc: 0.98684 | valid_accuracy: 0.8744  |  0:00:06s\n",
            "epoch 94 | loss: 0.00315 | train_auc: 0.98263 | train_accuracy: 0.9215  | valid_auc: 0.98684 | valid_accuracy: 0.8744  |  0:00:06s\n",
            "epoch 95 | loss: 0.0018  | train_auc: 0.98263 | train_accuracy: 0.92271 | valid_auc: 0.98684 | valid_accuracy: 0.87923 |  0:00:07s\n",
            "epoch 96 | loss: 0.00259 | train_auc: 0.98263 | train_accuracy: 0.92512 | valid_auc: 0.98684 | valid_accuracy: 0.88406 |  0:00:07s\n",
            "epoch 97 | loss: 0.0023  | train_auc: 0.98263 | train_accuracy: 0.92633 | valid_auc: 0.98684 | valid_accuracy: 0.88406 |  0:00:07s\n",
            "epoch 98 | loss: 0.00282 | train_auc: 0.98251 | train_accuracy: 0.92874 | valid_auc: 0.99561 | valid_accuracy: 0.88406 |  0:00:07s\n",
            "epoch 99 | loss: 0.00223 | train_auc: 0.98247 | train_accuracy: 0.92874 | valid_auc: 0.99552 | valid_accuracy: 0.88406 |  0:00:07s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_valid_accuracy = 0.88406\n",
            "Best weights from best epoch are automatically used!\n",
            "Loading weights from unsupervised pretraining\n",
            "epoch 0  | loss: 0.54745 | train_auc: 0.95258 | train_accuracy: 0.5     | valid_auc: 0.95567 | valid_accuracy: 0.56522 |  0:00:00s\n",
            "epoch 1  | loss: 0.17906 | train_auc: 0.95839 | train_accuracy: 0.49275 | valid_auc: 0.96154 | valid_accuracy: 0.56039 |  0:00:00s\n",
            "epoch 2  | loss: 0.1339  | train_auc: 0.95435 | train_accuracy: 0.49155 | valid_auc: 0.96154 | valid_accuracy: 0.56522 |  0:00:00s\n",
            "epoch 3  | loss: 0.10871 | train_auc: 0.94974 | train_accuracy: 0.49879 | valid_auc: 0.94505 | valid_accuracy: 0.56522 |  0:00:00s\n",
            "epoch 4  | loss: 0.08016 | train_auc: 0.93898 | train_accuracy: 0.50725 | valid_auc: 0.93407 | valid_accuracy: 0.56522 |  0:00:00s\n",
            "epoch 5  | loss: 0.07661 | train_auc: 0.91899 | train_accuracy: 0.51449 | valid_auc: 0.92308 | valid_accuracy: 0.56522 |  0:00:00s\n",
            "epoch 6  | loss: 0.06792 | train_auc: 0.90936 | train_accuracy: 0.52536 | valid_auc: 0.91209 | valid_accuracy: 0.57005 |  0:00:00s\n",
            "epoch 7  | loss: 0.07022 | train_auc: 0.88615 | train_accuracy: 0.53744 | valid_auc: 0.89011 | valid_accuracy: 0.57488 |  0:00:00s\n",
            "epoch 8  | loss: 0.05397 | train_auc: 0.8857  | train_accuracy: 0.54589 | valid_auc: 0.8956  | valid_accuracy: 0.57971 |  0:00:00s\n",
            "epoch 9  | loss: 0.05211 | train_auc: 0.87748 | train_accuracy: 0.55435 | valid_auc: 0.88462 | valid_accuracy: 0.58937 |  0:00:00s\n",
            "epoch 10 | loss: 0.04236 | train_auc: 0.86694 | train_accuracy: 0.5628  | valid_auc: 0.87912 | valid_accuracy: 0.6087  |  0:00:00s\n",
            "epoch 11 | loss: 0.05153 | train_auc: 0.85108 | train_accuracy: 0.57005 | valid_auc: 0.86813 | valid_accuracy: 0.61353 |  0:00:00s\n",
            "epoch 12 | loss: 0.0483  | train_auc: 0.83782 | train_accuracy: 0.57609 | valid_auc: 0.85411 | valid_accuracy: 0.61836 |  0:00:00s\n",
            "epoch 13 | loss: 0.03222 | train_auc: 0.84404 | train_accuracy: 0.58454 | valid_auc: 0.85762 | valid_accuracy: 0.63285 |  0:00:01s\n",
            "epoch 14 | loss: 0.03752 | train_auc: 0.84599 | train_accuracy: 0.59058 | valid_auc: 0.86775 | valid_accuracy: 0.63285 |  0:00:01s\n",
            "epoch 15 | loss: 0.03506 | train_auc: 0.83662 | train_accuracy: 0.59179 | valid_auc: 0.86027 | valid_accuracy: 0.64251 |  0:00:01s\n",
            "epoch 16 | loss: 0.03436 | train_auc: 0.7782  | train_accuracy: 0.57971 | valid_auc: 0.80774 | valid_accuracy: 0.63768 |  0:00:01s\n",
            "epoch 17 | loss: 0.03468 | train_auc: 0.77577 | train_accuracy: 0.60024 | valid_auc: 0.7923  | valid_accuracy: 0.66184 |  0:00:01s\n",
            "epoch 18 | loss: 0.0254  | train_auc: 0.80077 | train_accuracy: 0.61353 | valid_auc: 0.80921 | valid_accuracy: 0.69082 |  0:00:01s\n",
            "epoch 19 | loss: 0.02606 | train_auc: 0.78361 | train_accuracy: 0.6087  | valid_auc: 0.81276 | valid_accuracy: 0.6715  |  0:00:01s\n",
            "epoch 20 | loss: 0.01552 | train_auc: 0.76428 | train_accuracy: 0.59783 | valid_auc: 0.80305 | valid_accuracy: 0.64734 |  0:00:01s\n",
            "epoch 21 | loss: 0.01955 | train_auc: 0.72263 | train_accuracy: 0.58696 | valid_auc: 0.77837 | valid_accuracy: 0.64251 |  0:00:01s\n",
            "epoch 22 | loss: 0.01771 | train_auc: 0.75103 | train_accuracy: 0.60145 | valid_auc: 0.76724 | valid_accuracy: 0.64734 |  0:00:01s\n",
            "epoch 23 | loss: 0.01848 | train_auc: 0.77377 | train_accuracy: 0.61232 | valid_auc: 0.78841 | valid_accuracy: 0.66184 |  0:00:01s\n",
            "epoch 24 | loss: 0.01721 | train_auc: 0.77039 | train_accuracy: 0.62077 | valid_auc: 0.79874 | valid_accuracy: 0.67633 |  0:00:01s\n",
            "epoch 25 | loss: 0.01635 | train_auc: 0.78479 | train_accuracy: 0.62681 | valid_auc: 0.81778 | valid_accuracy: 0.70531 |  0:00:02s\n",
            "epoch 26 | loss: 0.01292 | train_auc: 0.80426 | train_accuracy: 0.64493 | valid_auc: 0.83649 | valid_accuracy: 0.7343  |  0:00:02s\n",
            "epoch 27 | loss: 0.02636 | train_auc: 0.8108  | train_accuracy: 0.65097 | valid_auc: 0.858   | valid_accuracy: 0.73913 |  0:00:02s\n",
            "epoch 28 | loss: 0.01417 | train_auc: 0.85215 | train_accuracy: 0.66787 | valid_auc: 0.86813 | valid_accuracy: 0.74396 |  0:00:02s\n",
            "epoch 29 | loss: 0.01204 | train_auc: 0.85454 | train_accuracy: 0.66667 | valid_auc: 0.84691 | valid_accuracy: 0.72947 |  0:00:02s\n",
            "epoch 30 | loss: 0.01052 | train_auc: 0.86602 | train_accuracy: 0.67995 | valid_auc: 0.84393 | valid_accuracy: 0.71498 |  0:00:02s\n",
            "epoch 31 | loss: 0.01676 | train_auc: 0.86565 | train_accuracy: 0.67512 | valid_auc: 0.83521 | valid_accuracy: 0.71014 |  0:00:02s\n",
            "epoch 32 | loss: 0.00844 | train_auc: 0.87296 | train_accuracy: 0.67995 | valid_auc: 0.88613 | valid_accuracy: 0.75362 |  0:00:02s\n",
            "epoch 33 | loss: 0.00779 | train_auc: 0.88162 | train_accuracy: 0.69082 | valid_auc: 0.88514 | valid_accuracy: 0.75845 |  0:00:02s\n",
            "epoch 34 | loss: 0.00789 | train_auc: 0.89573 | train_accuracy: 0.70652 | valid_auc: 0.89134 | valid_accuracy: 0.75845 |  0:00:02s\n",
            "epoch 35 | loss: 0.019   | train_auc: 0.90077 | train_accuracy: 0.70894 | valid_auc: 0.91209 | valid_accuracy: 0.76329 |  0:00:02s\n",
            "epoch 36 | loss: 0.00957 | train_auc: 0.9108  | train_accuracy: 0.71498 | valid_auc: 0.91209 | valid_accuracy: 0.76329 |  0:00:02s\n",
            "epoch 37 | loss: 0.00801 | train_auc: 0.91549 | train_accuracy: 0.71377 | valid_auc: 0.91758 | valid_accuracy: 0.77295 |  0:00:02s\n",
            "epoch 38 | loss: 0.01705 | train_auc: 0.91784 | train_accuracy: 0.72585 | valid_auc: 0.90659 | valid_accuracy: 0.77778 |  0:00:02s\n",
            "epoch 39 | loss: 0.01009 | train_auc: 0.9088  | train_accuracy: 0.72826 | valid_auc: 0.90228 | valid_accuracy: 0.77778 |  0:00:03s\n",
            "epoch 40 | loss: 0.01867 | train_auc: 0.91951 | train_accuracy: 0.73792 | valid_auc: 0.90792 | valid_accuracy: 0.77778 |  0:00:03s\n",
            "epoch 41 | loss: 0.01301 | train_auc: 0.92012 | train_accuracy: 0.74275 | valid_auc: 0.9173  | valid_accuracy: 0.79227 |  0:00:03s\n",
            "epoch 42 | loss: 0.00946 | train_auc: 0.9287  | train_accuracy: 0.75    | valid_auc: 0.92137 | valid_accuracy: 0.80193 |  0:00:03s\n",
            "epoch 43 | loss: 0.00484 | train_auc: 0.9298  | train_accuracy: 0.75483 | valid_auc: 0.92511 | valid_accuracy: 0.80676 |  0:00:03s\n",
            "epoch 44 | loss: 0.00723 | train_auc: 0.92786 | train_accuracy: 0.76208 | valid_auc: 0.9245  | valid_accuracy: 0.81159 |  0:00:03s\n",
            "epoch 45 | loss: 0.00985 | train_auc: 0.92745 | train_accuracy: 0.77295 | valid_auc: 0.9154  | valid_accuracy: 0.81643 |  0:00:03s\n",
            "epoch 46 | loss: 0.0058  | train_auc: 0.92887 | train_accuracy: 0.78019 | valid_auc: 0.92052 | valid_accuracy: 0.82126 |  0:00:03s\n",
            "epoch 47 | loss: 0.00389 | train_auc: 0.92944 | train_accuracy: 0.78865 | valid_auc: 0.92611 | valid_accuracy: 0.82609 |  0:00:03s\n",
            "epoch 48 | loss: 0.00398 | train_auc: 0.93103 | train_accuracy: 0.79348 | valid_auc: 0.93359 | valid_accuracy: 0.83575 |  0:00:03s\n",
            "epoch 49 | loss: 0.0046  | train_auc: 0.92931 | train_accuracy: 0.79952 | valid_auc: 0.93373 | valid_accuracy: 0.83575 |  0:00:03s\n",
            "epoch 50 | loss: 0.00556 | train_auc: 0.92931 | train_accuracy: 0.80918 | valid_auc: 0.93563 | valid_accuracy: 0.84058 |  0:00:03s\n",
            "epoch 51 | loss: 0.01297 | train_auc: 0.93032 | train_accuracy: 0.81763 | valid_auc: 0.93066 | valid_accuracy: 0.84541 |  0:00:03s\n",
            "epoch 52 | loss: 0.00607 | train_auc: 0.92783 | train_accuracy: 0.82126 | valid_auc: 0.93444 | valid_accuracy: 0.85024 |  0:00:03s\n",
            "epoch 53 | loss: 0.0047  | train_auc: 0.92445 | train_accuracy: 0.8128  | valid_auc: 0.92701 | valid_accuracy: 0.85024 |  0:00:04s\n",
            "epoch 54 | loss: 0.00365 | train_auc: 0.93556 | train_accuracy: 0.82246 | valid_auc: 0.93359 | valid_accuracy: 0.85507 |  0:00:04s\n",
            "epoch 55 | loss: 0.01321 | train_auc: 0.93634 | train_accuracy: 0.82367 | valid_auc: 0.94354 | valid_accuracy: 0.85507 |  0:00:04s\n",
            "epoch 56 | loss: 0.0069  | train_auc: 0.93816 | train_accuracy: 0.8285  | valid_auc: 0.9442  | valid_accuracy: 0.85507 |  0:00:04s\n",
            "epoch 57 | loss: 0.00453 | train_auc: 0.93704 | train_accuracy: 0.82488 | valid_auc: 0.94558 | valid_accuracy: 0.8599  |  0:00:04s\n",
            "epoch 58 | loss: 0.00452 | train_auc: 0.9375  | train_accuracy: 0.8285  | valid_auc: 0.94586 | valid_accuracy: 0.8599  |  0:00:04s\n",
            "epoch 59 | loss: 0.00479 | train_auc: 0.93773 | train_accuracy: 0.8285  | valid_auc: 0.94605 | valid_accuracy: 0.8599  |  0:00:04s\n",
            "epoch 60 | loss: 0.00417 | train_auc: 0.93936 | train_accuracy: 0.82971 | valid_auc: 0.94624 | valid_accuracy: 0.85507 |  0:00:04s\n",
            "epoch 61 | loss: 0.00344 | train_auc: 0.93924 | train_accuracy: 0.82971 | valid_auc: 0.94643 | valid_accuracy: 0.86473 |  0:00:04s\n",
            "epoch 62 | loss: 0.00188 | train_auc: 0.93856 | train_accuracy: 0.83213 | valid_auc: 0.94643 | valid_accuracy: 0.86957 |  0:00:04s\n",
            "epoch 63 | loss: 0.0059  | train_auc: 0.93791 | train_accuracy: 0.83575 | valid_auc: 0.94562 | valid_accuracy: 0.86957 |  0:00:04s\n",
            "epoch 64 | loss: 0.00399 | train_auc: 0.93865 | train_accuracy: 0.83816 | valid_auc: 0.94539 | valid_accuracy: 0.8744  |  0:00:04s\n",
            "epoch 65 | loss: 0.00315 | train_auc: 0.94193 | train_accuracy: 0.843   | valid_auc: 0.94297 | valid_accuracy: 0.8744  |  0:00:04s\n",
            "epoch 66 | loss: 0.00833 | train_auc: 0.94089 | train_accuracy: 0.8442  | valid_auc: 0.93525 | valid_accuracy: 0.87923 |  0:00:04s\n",
            "epoch 67 | loss: 0.00235 | train_auc: 0.93926 | train_accuracy: 0.85145 | valid_auc: 0.93246 | valid_accuracy: 0.87923 |  0:00:05s\n",
            "epoch 68 | loss: 0.00416 | train_auc: 0.93914 | train_accuracy: 0.85024 | valid_auc: 0.92672 | valid_accuracy: 0.8744  |  0:00:05s\n",
            "epoch 69 | loss: 0.00208 | train_auc: 0.94261 | train_accuracy: 0.84903 | valid_auc: 0.93236 | valid_accuracy: 0.86957 |  0:00:05s\n",
            "epoch 70 | loss: 0.00229 | train_auc: 0.94349 | train_accuracy: 0.85024 | valid_auc: 0.9334  | valid_accuracy: 0.87923 |  0:00:05s\n",
            "epoch 71 | loss: 0.00415 | train_auc: 0.94147 | train_accuracy: 0.85386 | valid_auc: 0.92838 | valid_accuracy: 0.88889 |  0:00:05s\n",
            "epoch 72 | loss: 0.00206 | train_auc: 0.94104 | train_accuracy: 0.84541 | valid_auc: 0.9272  | valid_accuracy: 0.87923 |  0:00:05s\n",
            "epoch 73 | loss: 0.00212 | train_auc: 0.94101 | train_accuracy: 0.85145 | valid_auc: 0.9244  | valid_accuracy: 0.86957 |  0:00:05s\n",
            "epoch 74 | loss: 0.00218 | train_auc: 0.94072 | train_accuracy: 0.843   | valid_auc: 0.92478 | valid_accuracy: 0.87923 |  0:00:05s\n",
            "epoch 75 | loss: 0.00477 | train_auc: 0.94223 | train_accuracy: 0.84541 | valid_auc: 0.9236  | valid_accuracy: 0.86473 |  0:00:05s\n",
            "epoch 76 | loss: 0.00332 | train_auc: 0.94132 | train_accuracy: 0.84179 | valid_auc: 0.91938 | valid_accuracy: 0.86957 |  0:00:05s\n",
            "epoch 77 | loss: 0.00332 | train_auc: 0.94195 | train_accuracy: 0.8442  | valid_auc: 0.92497 | valid_accuracy: 0.8599  |  0:00:05s\n",
            "epoch 78 | loss: 0.00458 | train_auc: 0.94136 | train_accuracy: 0.84058 | valid_auc: 0.92099 | valid_accuracy: 0.84541 |  0:00:05s\n",
            "epoch 79 | loss: 0.00172 | train_auc: 0.94292 | train_accuracy: 0.84179 | valid_auc: 0.91929 | valid_accuracy: 0.83575 |  0:00:05s\n",
            "epoch 80 | loss: 0.00176 | train_auc: 0.94139 | train_accuracy: 0.843   | valid_auc: 0.9217  | valid_accuracy: 0.83575 |  0:00:05s\n",
            "epoch 81 | loss: 0.00572 | train_auc: 0.93449 | train_accuracy: 0.84179 | valid_auc: 0.9118  | valid_accuracy: 0.84058 |  0:00:05s\n",
            "\n",
            "Early stopping occurred at epoch 81 with best_epoch = 71 and best_valid_accuracy = 0.88889\n",
            "Best weights from best epoch are automatically used!\n",
            "Loading weights from unsupervised pretraining\n",
            "epoch 0  | loss: 0.58189 | train_auc: 0.91664 | train_accuracy: 0.52174 | valid_auc: 0.91322 | valid_accuracy: 0.55556 |  0:00:00s\n",
            "epoch 1  | loss: 0.13862 | train_auc: 0.86369 | train_accuracy: 0.48913 | valid_auc: 0.85223 | valid_accuracy: 0.51208 |  0:00:00s\n",
            "epoch 2  | loss: 0.09286 | train_auc: 0.9461  | train_accuracy: 0.50242 | valid_auc: 0.94271 | valid_accuracy: 0.5314  |  0:00:00s\n",
            "epoch 3  | loss: 0.0821  | train_auc: 0.93624 | train_accuracy: 0.50242 | valid_auc: 0.93807 | valid_accuracy: 0.53623 |  0:00:00s\n",
            "epoch 4  | loss: 0.07298 | train_auc: 0.93198 | train_accuracy: 0.51087 | valid_auc: 0.93367 | valid_accuracy: 0.54589 |  0:00:00s\n",
            "epoch 5  | loss: 0.06767 | train_auc: 0.93556 | train_accuracy: 0.5157  | valid_auc: 0.93878 | valid_accuracy: 0.55072 |  0:00:00s\n",
            "epoch 6  | loss: 0.06771 | train_auc: 0.93198 | train_accuracy: 0.52053 | valid_auc: 0.93878 | valid_accuracy: 0.56039 |  0:00:00s\n",
            "epoch 7  | loss: 0.0638  | train_auc: 0.93198 | train_accuracy: 0.53261 | valid_auc: 0.93367 | valid_accuracy: 0.57005 |  0:00:00s\n",
            "epoch 8  | loss: 0.06294 | train_auc: 0.91399 | train_accuracy: 0.53744 | valid_auc: 0.90067 | valid_accuracy: 0.57488 |  0:00:00s\n",
            "epoch 9  | loss: 0.04221 | train_auc: 0.89986 | train_accuracy: 0.54348 | valid_auc: 0.87559 | valid_accuracy: 0.57971 |  0:00:00s\n",
            "epoch 10 | loss: 0.04092 | train_auc: 0.88386 | train_accuracy: 0.54831 | valid_auc: 0.86529 | valid_accuracy: 0.57971 |  0:00:00s\n",
            "epoch 11 | loss: 0.02869 | train_auc: 0.89154 | train_accuracy: 0.55556 | valid_auc: 0.85335 | valid_accuracy: 0.57971 |  0:00:00s\n",
            "epoch 12 | loss: 0.03564 | train_auc: 0.89019 | train_accuracy: 0.56159 | valid_auc: 0.85419 | valid_accuracy: 0.57971 |  0:00:00s\n",
            "epoch 13 | loss: 0.03779 | train_auc: 0.89323 | train_accuracy: 0.57367 | valid_auc: 0.87184 | valid_accuracy: 0.58454 |  0:00:01s\n",
            "epoch 14 | loss: 0.02949 | train_auc: 0.8977  | train_accuracy: 0.57971 | valid_auc: 0.87343 | valid_accuracy: 0.58454 |  0:00:01s\n",
            "epoch 15 | loss: 0.02619 | train_auc: 0.9062  | train_accuracy: 0.58937 | valid_auc: 0.86529 | valid_accuracy: 0.5942  |  0:00:01s\n",
            "epoch 16 | loss: 0.02218 | train_auc: 0.90695 | train_accuracy: 0.59541 | valid_auc: 0.86435 | valid_accuracy: 0.6087  |  0:00:01s\n",
            "epoch 17 | loss: 0.01834 | train_auc: 0.90487 | train_accuracy: 0.60145 | valid_auc: 0.87062 | valid_accuracy: 0.61353 |  0:00:01s\n",
            "epoch 18 | loss: 0.01973 | train_auc: 0.90031 | train_accuracy: 0.60507 | valid_auc: 0.86987 | valid_accuracy: 0.61353 |  0:00:01s\n",
            "epoch 19 | loss: 0.02068 | train_auc: 0.89938 | train_accuracy: 0.61353 | valid_auc: 0.86842 | valid_accuracy: 0.61353 |  0:00:01s\n",
            "epoch 20 | loss: 0.01854 | train_auc: 0.90013 | train_accuracy: 0.62077 | valid_auc: 0.85808 | valid_accuracy: 0.61353 |  0:00:01s\n",
            "epoch 21 | loss: 0.01635 | train_auc: 0.90495 | train_accuracy: 0.6256  | valid_auc: 0.85897 | valid_accuracy: 0.62802 |  0:00:01s\n",
            "epoch 22 | loss: 0.01474 | train_auc: 0.9048  | train_accuracy: 0.63043 | valid_auc: 0.85209 | valid_accuracy: 0.63768 |  0:00:01s\n",
            "epoch 23 | loss: 0.02136 | train_auc: 0.90425 | train_accuracy: 0.63768 | valid_auc: 0.8482  | valid_accuracy: 0.64734 |  0:00:01s\n",
            "epoch 24 | loss: 0.01437 | train_auc: 0.90535 | train_accuracy: 0.6401  | valid_auc: 0.86444 | valid_accuracy: 0.65217 |  0:00:01s\n",
            "epoch 25 | loss: 0.01454 | train_auc: 0.89695 | train_accuracy: 0.6558  | valid_auc: 0.85368 | valid_accuracy: 0.66184 |  0:00:01s\n",
            "epoch 26 | loss: 0.01661 | train_auc: 0.89272 | train_accuracy: 0.66184 | valid_auc: 0.83369 | valid_accuracy: 0.66667 |  0:00:01s\n",
            "epoch 27 | loss: 0.01595 | train_auc: 0.88443 | train_accuracy: 0.66425 | valid_auc: 0.83257 | valid_accuracy: 0.66667 |  0:00:02s\n",
            "epoch 28 | loss: 0.00869 | train_auc: 0.88198 | train_accuracy: 0.67391 | valid_auc: 0.8277  | valid_accuracy: 0.6715  |  0:00:02s\n",
            "epoch 29 | loss: 0.01581 | train_auc: 0.86899 | train_accuracy: 0.68237 | valid_auc: 0.83145 | valid_accuracy: 0.68116 |  0:00:02s\n",
            "epoch 30 | loss: 0.00706 | train_auc: 0.86948 | train_accuracy: 0.69686 | valid_auc: 0.81909 | valid_accuracy: 0.68116 |  0:00:02s\n",
            "epoch 31 | loss: 0.00758 | train_auc: 0.86665 | train_accuracy: 0.70411 | valid_auc: 0.81445 | valid_accuracy: 0.68599 |  0:00:02s\n",
            "epoch 32 | loss: 0.01126 | train_auc: 0.86577 | train_accuracy: 0.70894 | valid_auc: 0.82082 | valid_accuracy: 0.69082 |  0:00:02s\n",
            "epoch 33 | loss: 0.00599 | train_auc: 0.86718 | train_accuracy: 0.71981 | valid_auc: 0.82265 | valid_accuracy: 0.69082 |  0:00:02s\n",
            "epoch 34 | loss: 0.00593 | train_auc: 0.86983 | train_accuracy: 0.73068 | valid_auc: 0.81993 | valid_accuracy: 0.70048 |  0:00:02s\n",
            "epoch 35 | loss: 0.00495 | train_auc: 0.87009 | train_accuracy: 0.73309 | valid_auc: 0.82414 | valid_accuracy: 0.70048 |  0:00:02s\n",
            "epoch 36 | loss: 0.00664 | train_auc: 0.87344 | train_accuracy: 0.73671 | valid_auc: 0.83013 | valid_accuracy: 0.71014 |  0:00:02s\n",
            "epoch 37 | loss: 0.00399 | train_auc: 0.87422 | train_accuracy: 0.73913 | valid_auc: 0.82288 | valid_accuracy: 0.71981 |  0:00:02s\n",
            "epoch 38 | loss: 0.00484 | train_auc: 0.87328 | train_accuracy: 0.74275 | valid_auc: 0.82307 | valid_accuracy: 0.71981 |  0:00:02s\n",
            "epoch 39 | loss: 0.00329 | train_auc: 0.87456 | train_accuracy: 0.74638 | valid_auc: 0.82527 | valid_accuracy: 0.72464 |  0:00:02s\n",
            "epoch 40 | loss: 0.00265 | train_auc: 0.88029 | train_accuracy: 0.75121 | valid_auc: 0.82606 | valid_accuracy: 0.72464 |  0:00:03s\n",
            "epoch 41 | loss: 0.00516 | train_auc: 0.87852 | train_accuracy: 0.75845 | valid_auc: 0.83168 | valid_accuracy: 0.72464 |  0:00:03s\n",
            "epoch 42 | loss: 0.00278 | train_auc: 0.87798 | train_accuracy: 0.76208 | valid_auc: 0.83093 | valid_accuracy: 0.73913 |  0:00:03s\n",
            "epoch 43 | loss: 0.00438 | train_auc: 0.87795 | train_accuracy: 0.76691 | valid_auc: 0.83992 | valid_accuracy: 0.74396 |  0:00:03s\n",
            "epoch 44 | loss: 0.00299 | train_auc: 0.87883 | train_accuracy: 0.77053 | valid_auc: 0.84259 | valid_accuracy: 0.74879 |  0:00:03s\n",
            "epoch 45 | loss: 0.00219 | train_auc: 0.8797  | train_accuracy: 0.77415 | valid_auc: 0.85129 | valid_accuracy: 0.74879 |  0:00:03s\n",
            "epoch 46 | loss: 0.00257 | train_auc: 0.87692 | train_accuracy: 0.78261 | valid_auc: 0.85607 | valid_accuracy: 0.75845 |  0:00:03s\n",
            "epoch 47 | loss: 0.00816 | train_auc: 0.87795 | train_accuracy: 0.78382 | valid_auc: 0.86103 | valid_accuracy: 0.76812 |  0:00:03s\n",
            "epoch 48 | loss: 0.00231 | train_auc: 0.87575 | train_accuracy: 0.79348 | valid_auc: 0.86412 | valid_accuracy: 0.77295 |  0:00:03s\n",
            "epoch 49 | loss: 0.00662 | train_auc: 0.87746 | train_accuracy: 0.80072 | valid_auc: 0.86337 | valid_accuracy: 0.78744 |  0:00:03s\n",
            "epoch 50 | loss: 0.00578 | train_auc: 0.87895 | train_accuracy: 0.80556 | valid_auc: 0.86669 | valid_accuracy: 0.7971  |  0:00:03s\n",
            "epoch 51 | loss: 0.00215 | train_auc: 0.88157 | train_accuracy: 0.81039 | valid_auc: 0.87474 | valid_accuracy: 0.7971  |  0:00:03s\n",
            "epoch 52 | loss: 0.0036  | train_auc: 0.88572 | train_accuracy: 0.81039 | valid_auc: 0.87507 | valid_accuracy: 0.80193 |  0:00:03s\n",
            "epoch 53 | loss: 0.00471 | train_auc: 0.89089 | train_accuracy: 0.81401 | valid_auc: 0.87643 | valid_accuracy: 0.80193 |  0:00:04s\n",
            "epoch 54 | loss: 0.00287 | train_auc: 0.89153 | train_accuracy: 0.81884 | valid_auc: 0.88172 | valid_accuracy: 0.80676 |  0:00:04s\n",
            "epoch 55 | loss: 0.00229 | train_auc: 0.89365 | train_accuracy: 0.82005 | valid_auc: 0.89206 | valid_accuracy: 0.80676 |  0:00:04s\n",
            "epoch 56 | loss: 0.0065  | train_auc: 0.89861 | train_accuracy: 0.82488 | valid_auc: 0.89875 | valid_accuracy: 0.81159 |  0:00:04s\n",
            "epoch 57 | loss: 0.00422 | train_auc: 0.90066 | train_accuracy: 0.82971 | valid_auc: 0.90315 | valid_accuracy: 0.81159 |  0:00:04s\n",
            "epoch 58 | loss: 0.0046  | train_auc: 0.90363 | train_accuracy: 0.83333 | valid_auc: 0.90152 | valid_accuracy: 0.81643 |  0:00:04s\n",
            "epoch 59 | loss: 0.00489 | train_auc: 0.90462 | train_accuracy: 0.83575 | valid_auc: 0.90723 | valid_accuracy: 0.82609 |  0:00:04s\n",
            "epoch 60 | loss: 0.00272 | train_auc: 0.90853 | train_accuracy: 0.83816 | valid_auc: 0.90938 | valid_accuracy: 0.83092 |  0:00:04s\n",
            "epoch 61 | loss: 0.0053  | train_auc: 0.91122 | train_accuracy: 0.84058 | valid_auc: 0.90947 | valid_accuracy: 0.82609 |  0:00:04s\n",
            "epoch 62 | loss: 0.00665 | train_auc: 0.91186 | train_accuracy: 0.843   | valid_auc: 0.9076  | valid_accuracy: 0.81643 |  0:00:04s\n",
            "epoch 63 | loss: 0.00248 | train_auc: 0.91036 | train_accuracy: 0.83816 | valid_auc: 0.90489 | valid_accuracy: 0.81643 |  0:00:04s\n",
            "epoch 64 | loss: 0.00348 | train_auc: 0.91078 | train_accuracy: 0.83575 | valid_auc: 0.91144 | valid_accuracy: 0.82126 |  0:00:04s\n",
            "epoch 65 | loss: 0.00166 | train_auc: 0.91203 | train_accuracy: 0.83454 | valid_auc: 0.91004 | valid_accuracy: 0.82126 |  0:00:04s\n",
            "epoch 66 | loss: 0.00244 | train_auc: 0.91325 | train_accuracy: 0.84662 | valid_auc: 0.91547 | valid_accuracy: 0.83092 |  0:00:04s\n",
            "epoch 67 | loss: 0.0041  | train_auc: 0.91478 | train_accuracy: 0.85266 | valid_auc: 0.91528 | valid_accuracy: 0.84541 |  0:00:05s\n",
            "epoch 68 | loss: 0.00236 | train_auc: 0.91664 | train_accuracy: 0.85386 | valid_auc: 0.91907 | valid_accuracy: 0.84058 |  0:00:05s\n",
            "epoch 69 | loss: 0.00414 | train_auc: 0.92259 | train_accuracy: 0.8599  | valid_auc: 0.92487 | valid_accuracy: 0.83092 |  0:00:05s\n",
            "epoch 70 | loss: 0.00334 | train_auc: 0.92978 | train_accuracy: 0.8599  | valid_auc: 0.92759 | valid_accuracy: 0.83575 |  0:00:05s\n",
            "epoch 71 | loss: 0.00798 | train_auc: 0.93449 | train_accuracy: 0.86473 | valid_auc: 0.93952 | valid_accuracy: 0.83575 |  0:00:05s\n",
            "epoch 72 | loss: 0.00143 | train_auc: 0.93993 | train_accuracy: 0.86836 | valid_auc: 0.93433 | valid_accuracy: 0.84541 |  0:00:05s\n",
            "epoch 73 | loss: 0.00226 | train_auc: 0.94437 | train_accuracy: 0.87681 | valid_auc: 0.93966 | valid_accuracy: 0.85507 |  0:00:05s\n",
            "epoch 74 | loss: 0.00295 | train_auc: 0.94685 | train_accuracy: 0.88285 | valid_auc: 0.94322 | valid_accuracy: 0.86957 |  0:00:05s\n",
            "epoch 75 | loss: 0.00271 | train_auc: 0.94942 | train_accuracy: 0.88889 | valid_auc: 0.9494  | valid_accuracy: 0.86957 |  0:00:05s\n",
            "epoch 76 | loss: 0.00197 | train_auc: 0.95155 | train_accuracy: 0.89493 | valid_auc: 0.95132 | valid_accuracy: 0.87923 |  0:00:05s\n",
            "epoch 77 | loss: 0.00236 | train_auc: 0.95321 | train_accuracy: 0.89614 | valid_auc: 0.95277 | valid_accuracy: 0.87923 |  0:00:05s\n",
            "epoch 78 | loss: 0.00124 | train_auc: 0.95486 | train_accuracy: 0.89855 | valid_auc: 0.96335 | valid_accuracy: 0.87923 |  0:00:05s\n",
            "epoch 79 | loss: 0.00449 | train_auc: 0.95526 | train_accuracy: 0.89976 | valid_auc: 0.96415 | valid_accuracy: 0.88889 |  0:00:05s\n",
            "epoch 80 | loss: 0.00186 | train_auc: 0.95444 | train_accuracy: 0.89976 | valid_auc: 0.96461 | valid_accuracy: 0.88889 |  0:00:06s\n",
            "epoch 81 | loss: 0.0025  | train_auc: 0.95599 | train_accuracy: 0.90217 | valid_auc: 0.96518 | valid_accuracy: 0.88889 |  0:00:06s\n",
            "epoch 82 | loss: 0.00194 | train_auc: 0.9595  | train_accuracy: 0.90459 | valid_auc: 0.96518 | valid_accuracy: 0.89372 |  0:00:06s\n",
            "epoch 83 | loss: 0.00184 | train_auc: 0.95958 | train_accuracy: 0.9058  | valid_auc: 0.96522 | valid_accuracy: 0.89372 |  0:00:06s\n",
            "epoch 84 | loss: 0.00232 | train_auc: 0.95928 | train_accuracy: 0.9058  | valid_auc: 0.96503 | valid_accuracy: 0.89372 |  0:00:06s\n",
            "epoch 85 | loss: 0.0021  | train_auc: 0.95903 | train_accuracy: 0.907   | valid_auc: 0.96494 | valid_accuracy: 0.89372 |  0:00:06s\n",
            "epoch 86 | loss: 0.00206 | train_auc: 0.96285 | train_accuracy: 0.907   | valid_auc: 0.96499 | valid_accuracy: 0.89855 |  0:00:06s\n",
            "epoch 87 | loss: 0.00189 | train_auc: 0.96214 | train_accuracy: 0.90821 | valid_auc: 0.96377 | valid_accuracy: 0.90821 |  0:00:06s\n",
            "epoch 88 | loss: 0.00142 | train_auc: 0.96173 | train_accuracy: 0.91063 | valid_auc: 0.96358 | valid_accuracy: 0.91304 |  0:00:06s\n",
            "epoch 89 | loss: 0.00185 | train_auc: 0.96122 | train_accuracy: 0.91063 | valid_auc: 0.96274 | valid_accuracy: 0.91304 |  0:00:06s\n",
            "epoch 90 | loss: 0.00539 | train_auc: 0.96091 | train_accuracy: 0.91184 | valid_auc: 0.96223 | valid_accuracy: 0.91304 |  0:00:06s\n",
            "epoch 91 | loss: 0.00145 | train_auc: 0.96168 | train_accuracy: 0.91425 | valid_auc: 0.96209 | valid_accuracy: 0.92271 |  0:00:06s\n",
            "epoch 92 | loss: 0.00124 | train_auc: 0.96539 | train_accuracy: 0.91667 | valid_auc: 0.96199 | valid_accuracy: 0.92271 |  0:00:06s\n",
            "epoch 93 | loss: 0.00274 | train_auc: 0.96605 | train_accuracy: 0.91787 | valid_auc: 0.96068 | valid_accuracy: 0.92754 |  0:00:06s\n",
            "epoch 94 | loss: 0.00123 | train_auc: 0.96615 | train_accuracy: 0.91787 | valid_auc: 0.96031 | valid_accuracy: 0.93237 |  0:00:07s\n",
            "epoch 95 | loss: 0.00121 | train_auc: 0.96701 | train_accuracy: 0.92029 | valid_auc: 0.96021 | valid_accuracy: 0.93237 |  0:00:07s\n",
            "epoch 96 | loss: 0.00114 | train_auc: 0.96704 | train_accuracy: 0.92271 | valid_auc: 0.96031 | valid_accuracy: 0.93237 |  0:00:07s\n",
            "epoch 97 | loss: 0.00161 | train_auc: 0.96819 | train_accuracy: 0.92391 | valid_auc: 0.9604  | valid_accuracy: 0.93237 |  0:00:07s\n",
            "epoch 98 | loss: 0.0013  | train_auc: 0.96824 | train_accuracy: 0.92391 | valid_auc: 0.96059 | valid_accuracy: 0.93237 |  0:00:07s\n",
            "epoch 99 | loss: 0.00115 | train_auc: 0.96947 | train_accuracy: 0.92391 | valid_auc: 0.96078 | valid_accuracy: 0.93237 |  0:00:07s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 94 and best_valid_accuracy = 0.93237\n",
            "Best weights from best epoch are automatically used!\n",
            "accuracy score is 0.85000, roc auc score is 0.93613 and recall score is 0.80000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0EePj6K8Ti1",
        "outputId": "54e87349-6a3f-4d3f-ed1f-3a5b61de3ed2"
      },
      "source": [
        "cf_matrix = ensemble(results_tabnet, results_linear, results_tree, test_y)\n",
        "print(\"final confusion matrix is:\")\n",
        "print(cf_matrix)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final confusion matrix is:\n",
            "[[506  19]\n",
            " [  3  12]]\n"
          ]
        }
      ]
    }
  ]
}